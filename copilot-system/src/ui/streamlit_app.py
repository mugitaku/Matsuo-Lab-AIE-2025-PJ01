import streamlit as st
import os
from pathlib import Path

from ..response_engine.qa_engine import QAEngine, ResponseMode
from ..response_engine.hint_generator import HintGenerator
from ..knowledge_base.retriever import KnowledgeRetriever


# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="æ¼”ç¿’ã‚µãƒãƒ¼ãƒˆCopilot",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "qa_engine" not in st.session_state:
    st.session_state.qa_engine = QAEngine()
    st.session_state.hint_generator = HintGenerator()
    st.session_state.retriever = KnowledgeRetriever()
    st.session_state.messages = []
    st.session_state.mode = ResponseMode.NORMAL

# ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒ˜ãƒƒãƒ€ãƒ¼
st.title("ğŸ“ æ¼”ç¿’ã‚µãƒãƒ¼ãƒˆCopilot")
st.markdown("ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°æ¼”ç¿’ã®è³ªå•ã«ãŠç­”ãˆã—ã¾ã™ã€‚")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("è¨­å®š")
    
    # ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    mode_option = st.radio(
        "å¿œç­”ãƒ¢ãƒ¼ãƒ‰",
        ["é€šå¸¸ãƒ¢ãƒ¼ãƒ‰", "ãƒ’ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰"],
        help="é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: ç›´æ¥çš„ãªå›ç­”ã‚’æä¾›\nãƒ’ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰: æ®µéšçš„ãªãƒ’ãƒ³ãƒˆã‚’æä¾›"
    )
    
    if mode_option == "ãƒ’ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰":
        st.session_state.qa_engine.set_mode(ResponseMode.HINT)
        st.session_state.mode = ResponseMode.HINT
    else:
        st.session_state.qa_engine.set_mode(ResponseMode.NORMAL)
        st.session_state.mode = ResponseMode.NORMAL
    
    st.divider()
    
    # æ¼”ç¿’è³‡æ–™ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    st.header("æ¼”ç¿’è³‡æ–™ã®ç®¡ç†")
    uploaded_files = st.file_uploader(
        "æ¼”ç¿’è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=['pdf', 'txt', 'md', 'py'],
        accept_multiple_files=True
    )
    
    if uploaded_files:
        upload_dir = Path("data/exercises/uploaded")
        upload_dir.mkdir(parents=True, exist_ok=True)
        
        for uploaded_file in uploaded_files:
            file_path = upload_dir / uploaded_file.name
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            st.success(f"âœ… {uploaded_file.name} ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ›´æ–°
        if st.button("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°"):
            with st.spinner("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°ä¸­..."):
                count = st.session_state.retriever.index_documents(str(upload_dir))
                st.success(f"âœ… {count}å€‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã—ã¾ã—ãŸ")
    
    st.divider()
    
    # ä¼šè©±å±¥æ­´ã®ã‚¯ãƒªã‚¢
    if st.button("ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.messages = []
        st.session_state.qa_engine.clear_history()
        st.session_state.hint_generator.reset_hint_level()
        st.rerun()

# ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒƒãƒˆç”»é¢
st.header("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆ")

# ä¼šè©±å±¥æ­´ã®è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        
        # ãƒ’ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«ã®è¡¨ç¤º
        if message.get("hint_level"):
            st.caption(f"ãƒ’ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«: {message['hint_level']}/3")

# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
if prompt := st.chat_input("æ¼”ç¿’ã«é–¢ã™ã‚‹è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”
    with st.chat_message("assistant"):
        with st.spinner("è€ƒãˆä¸­..."):
            if st.session_state.mode == ResponseMode.HINT:
                # ãƒ’ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ
                hint_response = st.session_state.hint_generator.generate_hint(prompt)
                response_text = hint_response["hint"]
                hint_level = hint_response["level"]
                
                st.markdown(response_text)
                st.caption(f"ãƒ’ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«: {hint_level}/3")
                
                # æ¬¡ã®ãƒ¬ãƒ™ãƒ«ã®ãƒ’ãƒ³ãƒˆãƒœã‚¿ãƒ³
                if hint_response["next_level_available"]:
                    if st.button("ã‚‚ã†å°‘ã—è©³ã—ã„ãƒ’ãƒ³ãƒˆã‚’è¦‹ã‚‹"):
                        next_hint = st.session_state.hint_generator.generate_hint(prompt)
                        st.markdown(next_hint["hint"])
                        st.caption(f"ãƒ’ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«: {next_hint['level']}/3")
                
                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½åŠ 
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": response_text,
                    "hint_level": hint_level
                })
            else:
                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ
                response = st.session_state.qa_engine.answer(prompt)
                response_text = response["response"]
                
                st.markdown(response_text)
                
                # å‚ç…§ã—ãŸæ–‡æ›¸ã‚’è¡¨ç¤º
                if response.get("retrieved_documents"):
                    with st.expander("å‚ç…§ã—ãŸæ–‡æ›¸"):
                        for i, doc in enumerate(response["retrieved_documents"]):
                            st.caption(f"æ–‡æ›¸ {i+1}: {doc['metadata'].get('source', 'Unknown')}")
                            st.text(doc["content"])
                
                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½åŠ 
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": response_text
                })

# ãƒ•ãƒƒã‚¿ãƒ¼
st.divider()
st.caption("ğŸ¤– æ¼”ç¿’ã‚µãƒãƒ¼ãƒˆCopilot - AI ã«ã‚ˆã‚‹å­¦ç¿’æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ ")